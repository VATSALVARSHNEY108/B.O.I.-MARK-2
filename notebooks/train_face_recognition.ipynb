{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ VATSAL AI - Face Recognition Training\n",
    "\n",
    "This notebook trains the face recognition system to recognize you!\n",
    "\n",
    "## Steps:\n",
    "1. Load training images from `biometric_data/faces/vatsal/training/`\n",
    "2. Extract and process faces\n",
    "3. Train LBPH face recognition model\n",
    "4. Save trained model\n",
    "5. Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_PATH = \"biometric_data/faces\"\n",
    "MODEL_PATH = \"biometric_data/faces/models/face_model.yml\"\n",
    "LABELS_PATH = \"biometric_data/faces/models/labels.pkl\"\n",
    "\n",
    "print(f\"Training data: {TRAINING_DATA_PATH}\")\n",
    "print(f\"Model will be saved to: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Initialize Face Detection and Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    ")\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create(\n",
    "    radius=1,\n",
    "    neighbors=8,\n",
    "    grid_x=8,\n",
    "    grid_y=8\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Face detector and recognizer initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì∏ Load and Process Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìÇ Loading training images...\\n\")\n",
    "\n",
    "faces = []\n",
    "labels_list = []\n",
    "label_mapping = {}\n",
    "label_counter = 0\n",
    "\n",
    "for person_name in os.listdir(TRAINING_DATA_PATH):\n",
    "    person_folder = os.path.join(TRAINING_DATA_PATH, person_name, \"training\")\n",
    "    \n",
    "    if not os.path.isdir(person_folder):\n",
    "        continue\n",
    "    \n",
    "    if person_name not in label_mapping:\n",
    "        label_mapping[person_name] = label_counter\n",
    "        label_counter += 1\n",
    "    \n",
    "    person_label = label_mapping[person_name]\n",
    "    print(f\"üë§ Processing {person_name} (label: {person_label})\")\n",
    "    \n",
    "    image_files = [f for f in os.listdir(person_folder) \n",
    "                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    total_images = len(image_files)\n",
    "    processed = 0\n",
    "    face_count = 0\n",
    "    \n",
    "    for idx, image_file in enumerate(image_files):\n",
    "        image_path = os.path.join(person_folder, image_file)\n",
    "        \n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            detected_faces = face_cascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=5,\n",
    "                minSize=(100, 100)\n",
    "            )\n",
    "            \n",
    "            for (x, y, w, h) in detected_faces:\n",
    "                face_roi = gray[y:y+h, x:x+w]\n",
    "                face_roi = cv2.resize(face_roi, (200, 200))\n",
    "                face_roi = cv2.equalizeHist(face_roi)\n",
    "                \n",
    "                faces.append(face_roi)\n",
    "                labels_list.append(person_label)\n",
    "                face_count += 1\n",
    "                \n",
    "                flipped = cv2.flip(face_roi, 1)\n",
    "                faces.append(flipped)\n",
    "                labels_list.append(person_label)\n",
    "                face_count += 1\n",
    "            \n",
    "            processed += 1\n",
    "            \n",
    "            if (idx + 1) % 50 == 0:\n",
    "                print(f\"   Processed {idx + 1}/{total_images} images... ({face_count} faces)\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Error processing {image_file}: {e}\")\n",
    "    \n",
    "    print(f\"   ‚úÖ Loaded {face_count} face samples from {processed} images\\n\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üìä Training Statistics:\")\n",
    "print(f\"  Total face samples: {len(faces)}\")\n",
    "print(f\"  People to recognize: {len(label_mapping)}\")\n",
    "print(f\"  Label mapping: {label_mapping}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëÅÔ∏è Preview Sample Faces (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(faces) >= 10:\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    fig.suptitle('Sample Training Faces', fontsize=16)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(faces[i * 100], cmap='gray')\n",
    "        ax.set_title(f'Sample {i+1}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough faces to display samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(faces) == 0:\n",
    "    print(\"‚ùå No training images found! Add photos first.\")\n",
    "else:\n",
    "    print(\"üß† Training face recognition model...\")\n",
    "    print(\"   This may take a minute...\\n\")\n",
    "    \n",
    "    try:\n",
    "        recognizer.train(faces, np.array(labels_list))\n",
    "        \n",
    "        os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "        recognizer.save(MODEL_PATH)\n",
    "        \n",
    "        with open(LABELS_PATH, 'wb') as f:\n",
    "            pickle.dump(label_mapping, f)\n",
    "        \n",
    "        print(f\"‚úÖ Model saved to: {MODEL_PATH}\")\n",
    "        print(f\"‚úÖ Labels saved to: {LABELS_PATH}\")\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"üéâ Training complete!\")\n",
    "        print(f\"\\nYou can now use the trained model to recognize:\")\n",
    "        for name, label in label_mapping.items():\n",
    "            print(f\"  üë§ {name.upper()} (label: {label})\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Quick Test (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing model on training samples...\\n\")\n",
    "\n",
    "reverse_labels = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "test_samples = min(10, len(faces))\n",
    "correct = 0\n",
    "\n",
    "for i in range(test_samples):\n",
    "    test_face = faces[i * 100]\n",
    "    expected_label = labels_list[i * 100]\n",
    "    \n",
    "    label, distance = recognizer.predict(test_face)\n",
    "    predicted_name = reverse_labels.get(label, \"Unknown\")\n",
    "    expected_name = reverse_labels.get(expected_label, \"Unknown\")\n",
    "    \n",
    "    match = \"‚úÖ\" if label == expected_label else \"‚ùå\"\n",
    "    print(f\"{match} Sample {i+1}: Predicted={predicted_name}, Expected={expected_name}, Distance={distance:.2f}\")\n",
    "    \n",
    "    if label == expected_label:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = (correct / test_samples) * 100\n",
    "print(f\"\\nQuick test accuracy: {accuracy:.1f}% ({correct}/{test_samples})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Next Steps\n",
    "\n",
    "Your face recognition model is now trained! You can:\n",
    "\n",
    "1. **Test with camera**: Run `python show_camera.py`\n",
    "2. **Adjust threshold**: Use `+` and `-` keys while camera is running\n",
    "3. **Add more training photos**: Add photos to `biometric_data/faces/vatsal/training/` and re-run this notebook\n",
    "\n",
    "## üìä Model Info\n",
    "- **Model file**: `biometric_data/faces/models/face_model.yml`\n",
    "- **Training samples**: " + str(len(faces)) + "\n",
    "- **Default threshold**: 48 (adjustable in camera app)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
