#!/usr/bin/env python3
"""
Test VATSAL's Hand Gesture Detection
Based on Vatsal's own gesture photos!
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)), 'modules'))

from modules.automation.opencv_hand_gesture_detector import OpenCVHandGestureDetector
import time

def main():
    print("=" * 70)
    print("VATSAL AI - Personal Gesture Recognition Test")
    print("=" * 70)
    print()
    print("Based on Vatsal's gesture photos!")
    print()
    print("Gestures to try:")
    print("  ğŸ‘ THUMBS UP - Shows approval, good job!")
    print("  âœŒï¸  PEACE SIGN - Victory, 2 or 3 fingers")
    print("  ğŸ‘‹ OPEN PALM - Activate voice listening (spread all 5 fingers)")
    print("  âœŠ FIST - Stop/Cancel")
    print()
    print("Tips for best detection:")
    print("  â€¢ Wear your yellow bracelet for better hand detection")
    print("  â€¢ Keep good lighting (like in your photos)")
    print("  â€¢ Show gestures clearly to the camera")
    print("  â€¢ Hold each gesture for 1-2 seconds")
    print()
    print("=" * 70)
    print()
    
    detector = OpenCVHandGestureDetector()
    
    def on_gesture(command):
        print(f"ğŸ¯ Gesture command received: {command}")
    
    detector.set_gesture_callback(on_gesture)
    
    print("ğŸš€ Starting detector...")
    result = detector.start(camera_index=0)
    
    if result['success']:
        print(f"âœ… {result['message']}")
        print()
        print("ğŸ‘€ Looking for Vatsal...")
        print("ğŸ’¡ TIP: Try all the gestures from your photos!")
        print()
        print("Press 'q' in the video window to quit")
        print()
        
        try:
            while detector.is_running():
                time.sleep(0.5)
        except KeyboardInterrupt:
            print("\n\nâš ï¸  Interrupted by user")
        
        detector.stop()
        
        # Show statistics
        stats = detector.get_stats()
        print("\n" + "=" * 70)
        print("ğŸ“Š Your Gesture Statistics:")
        print("=" * 70)
        print(f"  ğŸ‘¤ Faces detected: {stats['faces_detected']}")
        print(f"  ğŸ¯ Total gestures: {stats['gestures_detected']}")
        print(f"  ğŸ‘‹ Greetings: {stats['greetings_given']}")
        print(f"  âœ‹ Open palms: {stats['open_palm_detected']}")
        print(f"  ğŸ‘ Thumbs up: {stats['thumbs_up_detected']}")
        print(f"  âœŒï¸  Peace signs: {stats['peace_sign_detected']}")
        print(f"  âœŠ Fists: {stats['fist_detected']}")
        print("=" * 70)
        
        # Fun message based on stats
        if stats['thumbs_up_detected'] > 0:
            print("\nğŸ‘ Great job with the thumbs up!")
        if stats['peace_sign_detected'] > 0:
            print("âœŒï¸  Peace and victory!")
        if stats['open_palm_detected'] > 0:
            print("ğŸ‘‹ You activated voice listening!")
            
    else:
        print(f"âŒ {result['message']}")
        print("\nğŸ’¡ Make sure your webcam is connected")
    
    print("\nâœ… Test complete! Your gesture system is ready!")


if __name__ == "__main__":
    main()
